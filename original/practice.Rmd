# Practice Problems {#practice}

```{r setup, include=FALSE}
source("etc/common.R")
```

You need more practice with the functions in Chapter \@ref(tidyverse).
To begin,
open a fresh file and begin by loading the tidyverse
and the here package used to construct paths:

```{r fake-load-libraries, eval=FALSE}
library(tidyverse)
library(here)
```

Next,
use `here::here` to construct a path to a file and `readr::read_csv` to read that file:

```{r read-survey-data}
path = here::here("data", "person.csv")
person <- readr::read_csv(path)
```

We don't need to write out fully-qualified names—`here` and `read_csv` will do—but
we will use them to make it easier to see what comes from where.

Next,
have a look at the tibble `person`,
which contains some basic information about a group of foolhardy scientists
who ventured into the Antarctic in the 1920s and 1930s in search of things best left undisturbed:

```{r show-person}
person
```

How many rows and columns does this tibble contain?

```{r count-rows}
nrow(person)
```

```{r count-cols}
ncol(person)
```

(These names don't have a package prefix because they are built in.)
Let's show that information in a slightly nicer way
using `glue` to insert values into a string
and `print` to display the result:

```{r use-glue}
print(glue::glue("person has {nrow(person)} rows and {ncol(person)} columns"))
```

If we want to display several values,
we can use the function `paste` to combine the elements of a vector.
`colnames` gives us the names of a tibble's columns,
and `paste`'s `collapse` argument tells the function
to use a single space to separate concatenated values:

```{r use-colnames-and-paste}
print(glue::glue("person columns are {paste(colnames(person), collapse = ' ')}"))
```

Time for some data manipulation.
Let's get everyone's family and personal names:

```{r select-by-name}
dplyr::select(person, family_name, personal_name)
```

and then filter that list to keep only those that come in the first half of the alphabet:

```{r filter-with-two-conditions}
dplyr::select(person, family_name, personal_name) %>%
  dplyr::filter(family_name < "N")
```

It would be more consistent to rewrite this as:

```{r filter-consistently}
person %>%
  dplyr::select(family_name, personal_name) %>%
  dplyr::filter(family_name < "N")
```

It's easy to add a column that records the lengths of family names:

```{r mutate-name-length}
person %>%
  dplyr::mutate(name_length = stringr::str_length(family_name))
```

and then arrange in descending order:

```{r mutate-and-arrange}
person %>%
  dplyr::mutate(name_length = stringr::str_length(family_name)) %>%
  dplyr::arrange(dplyr::desc(name_length))
```

## Do we need even more practice?

Yes.
Yes, you do.
Let's load a slightly larger dataset:

```{r read-and-view}
measurements <- readr::read_csv(here::here("data", "measurements.csv"))
measurements
```

If we want an overview of our data's properties,
we can use the aptly-named `summarize` function:

```{r summarize}
dplyr::summarize(measurements)
```

Removing records with missing readings is straightforward:

```{r remove-reading-na}
measurements %>%
  dplyr::filter(!is.na(reading))
```

Removing rows that contain *any* NAs is equally easy,
though it may be statistically unsound:

```{r hidden-cleaned, echo=FALSE}
cleaned <- measurements %>%
  tidyr::drop_na()
```

We can now group our data by the quantity measured
and count the number of each—the column is named `n` automatically:

```{r group-by-quantity}
cleaned %>%
  dplyr::group_by(quantity) %>%
  dplyr::count()
```

How are the readings of each type distributed?

```{r min-ave-max}
cleaned %>%
  dplyr::group_by(quantity) %>%
  dplyr::summarize(low = min(reading),
                   mid = mean(reading),
                   high = max(reading))
```

After inspection,
we realize that most of the salinity measurements lie between 0 and 1,
but a handful range up to 100.
During a brief interval of lucidity,
the librarian who collected the battered notebooks from which the data was transcribed
informs us that one of the explorers recorded percentages rather than actual values.
We therefore decide to normalize all salinity measurements greater than 1.0 using `ifelse`
(a two-branch analog of `case_when`):

```{r rescale-salinity}
cleaned <- cleaned %>%
  dplyr::mutate(reading = ifelse(quantity == 'sal' & reading > 1.0,
                                 reading/100,
                                 reading))
cleaned
```

To answer our next set of questions,
we need data about when each site was visited.
Let's read `visited.csv` and discard entries that are missing the visit date:

```{r read-visited}
visited <- readr::read_csv(here::here("data", "visited.csv")) %>%
  dplyr::filter(!is.na(visit_date))
visited
```

and then combine that table with our cleaned measurement data.
We will use an [inner join](glossary.html#inner-join)
that matches records on the visit ID;
dplyr also provides other kinds of joins should we need them.

```{r join-two-tables}
combined <- visited %>%
  dplyr::inner_join(cleaned,
                    by = c("visit_id" = "visit_id"))
```

We can now find the date of the highest radiation reading at each site:

```{r dates-high-rad}
combined %>%
  dplyr::filter(quantity == "rad") %>%
  dplyr::group_by(site_id) %>%
  dplyr::mutate(max_rad = max(reading)) %>%
  dplyr::filter(reading == max_rad)
```

or:

```{r dates-high-rad-2}
combined %>%
  dplyr::filter(quantity == "rad") %>%
  dplyr::group_by(site_id) %>%
  dplyr::top_n(1, reading) %>%
  dplyr::select(site_id, visit_date, reading)
```

The function `dplyr::lag` shifts the values in a column.
We can use it to calculate the difference in radiation at each site
between visits:

```{r rad-change}
combined %>%
  dplyr::filter(quantity == "rad") %>%
  dplyr::group_by(site_id) %>%
  dplyr::mutate(delta_rad = reading - dplyr::lag(reading)) %>%
  dplyr::arrange(site_id, visit_date)
```

Going one step further,
we can create a list of sites at which radiation increased between any two visits:

```{r rad-increases}
combined %>%
  dplyr::filter(quantity == "rad") %>%
  dplyr::group_by(site_id) %>%
  dplyr::mutate(delta_rad = reading - dplyr::lag(reading)) %>%
  dplyr::filter(!is.na(delta_rad)) %>%
  dplyr::summarize(any_increase = any(delta_rad > 0)) %>%
  dplyr::filter(any_increase)
```

## Please may we create some charts?

Certainly.
We will use data on the mass and home range area (HRA) of various species from:

> Tamburello N, Côté IM, Dulvy NK (2015) Data from: Energy and the scaling of animal space use. Dryad Digital Repository.
> https://doi.org/10.5061/dryad.q5j65

```{r read-hra}
hra <- readr::read_csv(here::here("data", "home-range-database.csv"))
head(hra)
```

A few keystrokes show us how the masses of these animals are distributed:

```{r chart-mass}
ggplot2::ggplot(hra) +
  ggplot2::geom_histogram(mapping = aes(x = mean.mass.g))
```

The distribution becomes much clearer if we plot the logarithms of the masses,
which are helpfully precalculated in `log10.mass`:

```{r chart-log-mass}
ggplot2::ggplot(hra) +
  ggplot2::geom_histogram(mapping = aes(x = log10.mass))
```

Let's tidy that up a bit:

```{r change-visual}
ggplot2::ggplot(hra) +
  ggplot2::geom_histogram(mapping = aes(x = log10.mass), bins = 100) +
  ggplot2::ggtitle("Frequency of Species Masses") +
  ggplot2::xlab("Log10 of Mass") +
  ggplot2::ylab("Number of Species") +
  ggplot2::theme_minimal()
```

How are mass and home range area related?

```{r scatterplot}
ggplot2::ggplot(hra) +
  ggplot2::geom_point(mapping = aes(x = log10.mass, y = log10.hra))
```

Does the relationship depend on the class of animal?
(Here, we use the word "class" in the biological sense:
the class "aves" is birds.)

```{r colorize-scatterplot}
hra %>%
  dplyr::mutate(class_fct = as.factor(class)) %>%
  ggplot2::ggplot(mapping = aes(x = log10.mass, y = log10.hra, color = class_fct)) +
  ggplot2::geom_point(alpha = 0.5)
```

> **What's a Factor?**
>
> The code above creates a new column `class_fct`
> by converting the text values in `class` to a [factor](glossary.html#factor).
> Other languages call this an enumeration:
> we will discuss factors in more detail in Chapter \@ref(debt).

Our chart may be clearer if we display the [facets](glossary.html#facet) separately:

```{r facet-plot}
hra %>%
  dplyr::mutate(class_fct = as.factor(class)) %>%
  ggplot2::ggplot(mapping = aes(x = log10.mass, y = log10.hra, color = class_fct)) +
  ggplot2::geom_point(alpha = 0.5) +
  ggplot2::facet_wrap(~class_fct)
```

If we want to look at the mass-area relationship more closely for birds,
we can construct a regression line:

```{r fit-line}
hra %>%
  dplyr::filter(class == "aves") %>%
  ggplot2::ggplot(mapping = aes(x = log10.mass, y = log10.hra)) +
  ggplot2::geom_point(alpha = 0.5) +
  ggplot2::geom_smooth(method = lm, color = 'red')
```

Drilling down even further,
we can create a violin plot of mass by order for the birds
(where "order" is the biological division below "class"):

```{r violin-plot}
hra %>%
  dplyr::filter(class == "aves") %>%
  dplyr::mutate(order_fct = as.factor(order)) %>%
  ggplot2::ggplot(mapping = aes(x = order_fct, y = log10.mass, color = order_fct)) +
  ggplot2::geom_violin()
```

Changing just one line gives us a box plot instead:

```{r box-plot}
hra %>%
  dplyr::filter(class == "aves") %>%
  dplyr::mutate(order_fct = as.factor(order)) %>%
  ggplot2::ggplot(mapping = aes(x = order_fct, y = log10.mass, color = order_fct)) +
  ggplot2::geom_boxplot()
```

And if we want to save our chart to a file,
that's just one more call as well:

```{r save-file}
hra %>%
  dplyr::filter(class == "aves") %>%
  ggplot2::ggplot(mapping = aes(x = log10.mass, y = log10.hra)) +
  ggplot2::geom_point(alpha = 0.5) +
  ggplot2::geom_smooth(method = lm, color = 'red')
ggsave("/tmp/birds.png")
```

```{r links, child="etc/links.md"}
```
